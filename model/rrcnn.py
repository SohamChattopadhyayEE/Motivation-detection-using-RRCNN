# -*- coding: utf-8 -*-
"""1D-CNN_NORWAY.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g3hYWuKyN-0d3Ul4uBrHP4V94jOR99Xp
"""

#### MODEL :- 3 #####

import torch
import torch.nn as nn

class ResBlock(nn.Module):
  def __init__(self, num_ft = 64, kernel_size = 3, stride = 1, padding = 1):
    super(ResBlock, self).__init__()
    m = []
    for _ in range(2):
      m.append(nn.Conv1d(num_ft, num_ft, kernel_size, stride, padding))
      m.append(nn.BatchNorm1d(num_ft))
      m.append(nn.ReLU())
    self.body = nn.Sequential(*m)

  def forward(self, x):
    res = self.body(x)
    res += x
    return res





class ResedualEEGClassifier(nn.Module):
  def __init__(self, num_channels,  num_classes, num_res_ft = 64, num_res = 2, input_size = 16,
               hidden_size = 128, sequence_length = 16, num_layers = 1):
    super(ResedualEEGClassifier, self).__init__()
    self.conv = nn.Conv1d(num_channels, num_res_ft, kernel_size = 3, stride = 1, padding = 0)
    self.res = ResBlock()
    mat = []
    for _ in range(num_res):
      mat.append(ResBlock(num_ft = num_res_ft))
      mat.append(nn.RReLU())
    self.res_body = nn.Sequential(*mat) 

    self.avg = nn.AdaptiveAvgPool1d(1)
    self.maxpool = nn.MaxPool1d(1)

    self.fc = nn.Linear(num_res_ft, num_classes)
    self.clf = nn.Softmax()

  def forward(self, x):
    #print('x: ', x.shape)
    x = self.conv(x)
    #print('x_conv: ', x.shape)
    x = self.res_body(x)
    #print('x_res: ', x.shape)
    x = self.avg(x)
    x = torch.flatten(x)
    #print('flatten x: ', x.shape)
    x = self.fc(x)
    x = self.clf(x)
    return x

#### MODEL :- 4 #####

import torch
import torch.nn as nn

class ResBlock(nn.Module):
  def __init__(self, num_ft = 64, kernel_size = 3, stride = 1, padding = 1):
    super(ResBlock, self).__init__()
    m = []
    for _ in range(2):
      m.append(nn.Conv1d(num_ft, num_ft, kernel_size, stride, padding))
      m.append(nn.BatchNorm1d(num_ft))
      m.append(nn.ReLU())
    self.body = nn.Sequential(*m)

  def forward(self, x):
    res = self.body(x)
    res += x
    return res





class ResedualEEGClassifier_3(nn.Module):
  def __init__(self, num_channels,  num_classes, num_res_ft = 64, num_res = 2, input_size = 16,
               hidden_size = 128, sequence_length = 16, num_layers = 1):
    super(ResedualEEGClassifier_3, self).__init__()
    self.conv = nn.Conv1d(num_channels, num_res_ft, kernel_size = 3, stride = 1, padding = 0)
    self.res = ResBlock()
    mat = []
    for _ in range(num_res):
      mat.append(ResBlock(num_ft = num_res_ft))
      mat.append(nn.RReLU())
    self.res_body_1 = nn.Sequential(*mat) 

    self.conv2 = nn.Conv1d(num_res_ft, num_res_ft*2, kernel_size = 3, stride = 1, padding = 0)

    mat2 = []
    for _ in range(num_res):
      mat2.append(ResBlock(num_ft = num_res_ft*2))
      mat2.append(nn.RReLU())
    self.res_body_2 = nn.Sequential(*mat2) 
    self.conv3 = nn.Conv1d(num_res_ft*2, num_res_ft*4, kernel_size = 3, stride = 1, padding = 0)

    mat3 = []
    for _ in range(num_res):
      mat3.append(ResBlock(num_ft = num_res_ft*4))
      mat3.append(nn.RReLU())
    self.res_body_3 = nn.Sequential(*mat3) 
    self.conv4 = nn.Conv1d(num_res_ft*4, num_res_ft*8, kernel_size = 3, stride = 1, padding = 0)

    mat4 = []
    for _ in range(num_res):
      mat4.append(ResBlock(num_ft = num_res_ft*8))
      mat4.append(nn.RReLU())
    self.res_body_4 = nn.Sequential(*mat4) 

    self.avg = nn.AdaptiveAvgPool1d(1)
    self.maxpool = nn.MaxPool1d(1)

    self.fc = nn.Linear(num_res_ft*4, num_classes)
    self.clf = nn.Softmax()

  def forward(self, x):
    x = self.conv(x)
    x = self.res_body_1(x)
    x = self.conv2(x)
    x = self.res_body_2(x)
    x = self.conv3(x)
    x = self.res_body_3(x)
    #x = self.conv4(x)
    #x = self.res_body_4(x)
    x = self.avg(x)
    x = torch.flatten(x)
    x = self.fc(x)
    x = self.clf(x)
    return x

#### MODEL :- 5 #####

import torch
import torch.nn as nn

class ResBlock(nn.Module):
  def __init__(self, num_ft = 64, kernel_size = 3, stride = 1, padding = 1):
    super(ResBlock, self).__init__()
    m = []
    for _ in range(2):
      m.append(nn.Conv1d(num_ft, num_ft, kernel_size, stride, padding))
      m.append(nn.BatchNorm1d(num_ft))
      m.append(nn.ReLU())
    self.body = nn.Sequential(*m)

  def forward(self, x):
    res = self.body(x)
    res += x
    return res





class ResedualEEGClassifier_3Dense(nn.Module):
  def __init__(self, num_channels,  num_classes, num_res_ft = 64, num_res = 2, input_size = 16,
               hidden_size = 128, sequence_length = 16, num_layers = 1):
    super(ResedualEEGClassifier_3Dense, self).__init__()
    self.conv = nn.Conv1d(num_channels, num_res_ft, kernel_size = 3, stride = 1, padding = 1)
    self.res = ResBlock()
    mat = []
    for _ in range(num_res):
      mat.append(ResBlock(num_ft = num_res_ft))
      mat.append(nn.RReLU())
    self.res_body_1 = nn.Sequential(*mat) 

    self.conv2 = nn.Conv1d(num_res_ft, num_res_ft*2, kernel_size = 3, stride = 1, padding = 1)

    mat2 = []
    for _ in range(num_res):
      mat2.append(ResBlock(num_ft = num_res_ft*2))
      mat2.append(nn.RReLU())
    self.res_body_2 = nn.Sequential(*mat2) 
    self.conv3 = nn.Conv1d(num_res_ft*2, num_res_ft*4, kernel_size = 3, stride = 1, padding = 1)

    mat3 = []
    for _ in range(num_res):
      mat3.append(ResBlock(num_ft = num_res_ft*4))
      mat3.append(nn.RReLU())
    self.res_body_3 = nn.Sequential(*mat3) 
    self.conv4 = nn.Conv1d(num_res_ft*4, num_res_ft*8, kernel_size = 3, stride = 1, padding = 1)

    mat4 = []
    for _ in range(num_res):
      mat4.append(ResBlock(num_ft = num_res_ft*8))
      mat4.append(nn.RReLU())
    self.res_body_4 = nn.Sequential(*mat4) 

    self.avg = nn.AdaptiveAvgPool1d(1)
    self.maxpool = nn.MaxPool1d(1)

    self.fc = nn.Linear(num_res_ft*4, num_classes)
    self.clf = nn.Softmax()

  def forward(self, x):
    x_in = self.conv(x)
    x = self.res_body_1(x_in)
    x = x + x_in
    x = self.conv2(x)
    x1 = x
    x = self.res_body_2(x)
    x = x+x1
    x = self.conv3(x)
    x2 = x
    x = self.res_body_3(x)
    x = x + x2
    #x = self.conv4(x)
    #x = self.res_body_4(x)
    x = self.avg(x)
    x = torch.flatten(x)
    x = self.fc(x)
    x = self.clf(x)
    return x

#### MODEL :- 6 #####

import torch
import torch.nn as nn

class ResBlock(nn.Module):
  def __init__(self, num_ft = 64, kernel_size = 3, stride = 1, padding = 1):
    super(ResBlock, self).__init__()
    m = []
    for _ in range(2):
      m.append(nn.Conv1d(num_ft, num_ft, kernel_size, stride, padding))
      m.append(nn.BatchNorm1d(num_ft))
      m.append(nn.ReLU())
    self.body = nn.Sequential(*m)

  def forward(self, x):
    res = self.body(x)
    res += x
    return res





class ResedualEEGClassifier_3DenseV2(nn.Module):
  def __init__(self, num_channels,  num_classes, num_res_ft = 64, num_res = 2, input_size = 16,
               hidden_size = 128, sequence_length = 16, num_layers = 1):
    super(ResedualEEGClassifier_3DenseV2, self).__init__()
    self.conv = nn.Conv1d(num_channels, num_res_ft, kernel_size = 3, stride = 1, padding = 1)
    self.res = ResBlock()
    mat = []
    for _ in range(num_res):
      mat.append(ResBlock(num_ft = num_res_ft))
      mat.append(nn.RReLU())
    self.res_body_1 = nn.Sequential(*mat) 

    self.conv2 = nn.Conv1d(num_res_ft, num_res_ft*2, kernel_size = 3, stride = 1, padding = 1)

    mat2 = []
    for _ in range(num_res):
      mat2.append(ResBlock(num_ft = num_res_ft*2))
      mat2.append(nn.RReLU())
    self.res_body_2 = nn.Sequential(*mat2) 
    self.conv3 = nn.Conv1d(num_res_ft*2, num_res_ft*4, kernel_size = 3, stride = 1, padding = 1)

    mat3 = []
    for _ in range(num_res):
      mat3.append(ResBlock(num_ft = num_res_ft*4))
      mat3.append(nn.RReLU())
    self.res_body_3 = nn.Sequential(*mat3) 
    self.conv4 = nn.Conv1d(num_res_ft*4, num_res_ft*8, kernel_size = 3, stride = 1, padding = 1)

    mat4 = []
    for _ in range(num_res):
      mat4.append(ResBlock(num_ft = num_res_ft*8))
      mat4.append(nn.RReLU())
    self.res_body_4 = nn.Sequential(*mat4) 

    self.avg = nn.AdaptiveAvgPool1d(1)
    self.maxpool = nn.MaxPool1d(1)

    self.fc = nn.Linear(num_res_ft, num_classes)
    self.clf = nn.Softmax()

  def forward(self, x):
    x_in = self.conv(x)
    x = self.res_body_1(x_in)
    x1 = x_in + x
    x = self.res_body_1(x1)
    x2 = x + x1 + x_in
    x = self.res_body_1(x2)
    x3 = x + x2 + x1 + x_in
    #x = self.res_body_1(x3)
    #x4 = x + x3
    #x = self.res_body_1(x4)
    #x5 = x + x4
    x = self.avg(x3)
    x = torch.flatten(x)
    x = self.fc(x)
    x = self.clf(x)
    return x

##### MODEL :- 6 ####

import torch
import torch.nn as nn

class ResBlock(nn.Module):
  def __init__(self, num_ft = 64, kernel_size = 3, stride = 1, padding = 1):
    super(ResBlock, self).__init__()
    m = []
    for _ in range(2):
      m.append(nn.Conv1d(num_ft, num_ft, kernel_size, stride, padding))
      m.append(nn.BatchNorm1d(num_ft))
      m.append(nn.ReLU())
    self.body = nn.Sequential(*m)

  def forward(self, x):
    res = self.body(x)
    res += x
    return res





class ResedualEEGClassifier_3ALL(nn.Module):
  def __init__(self, num_channels,  num_classes, num_res_ft = 64, num_res = 2, input_size = 16,
               hidden_size = 128, sequence_length = 16, num_layers = 1):
    super(ResedualEEGClassifier_3ALL, self).__init__()
    self.conv = nn.Conv1d(num_channels, num_res_ft, kernel_size = 3, stride = 1, padding = 0)
    self.res = ResBlock()
    mat = []
    for _ in range(num_res):
      mat.append(ResBlock(num_ft = num_res_ft))
      mat.append(nn.RReLU())
    self.res_body_1 = nn.Sequential(*mat) 

    self.conv2 = nn.Conv1d(num_res_ft, num_res_ft*2, kernel_size = 3, stride = 1, padding = 0)

    mat2 = []
    for _ in range(num_res):
      mat2.append(ResBlock(num_ft = num_res_ft*2))
      mat2.append(nn.RReLU())
    self.res_body_2 = nn.Sequential(*mat2) 
    self.conv3 = nn.Conv1d(num_res_ft*2, num_res_ft*4, kernel_size = 3, stride = 1, padding = 0)

    mat3 = []
    for _ in range(num_res):
      mat3.append(ResBlock(num_ft = num_res_ft*4))
      mat3.append(nn.RReLU())
    self.res_body_3 = nn.Sequential(*mat3) 
    self.conv4 = nn.Conv1d(num_res_ft*4, num_res_ft*8, kernel_size = 3, stride = 1, padding = 0)

    mat4 = []
    for _ in range(num_res):
      mat4.append(ResBlock(num_ft = num_res_ft*8))
      mat4.append(nn.RReLU())
    self.res_body_4 = nn.Sequential(*mat4) 

    self.avg = nn.AdaptiveAvgPool1d(1)
    self.maxpool = nn.MaxPool1d(1)

    self.fc = nn.Linear(num_res_ft*7, num_classes)
    self.clf = nn.Softmax()

  def forward(self, x):
    x = self.conv(x)
    x = self.res_body_1(x)
    x1 = self.avg(x)
    x = self.conv2(x)
    x = self.res_body_2(x)
    x2 = self.avg(x)
    x = self.conv3(x)
    x = self.res_body_3(x)
    #x = self.conv4(x)
    #x = self.res_body_4(x)
    x = self.avg(x)
    xf = torch.cat((x,x1), dim = 1)
    xf = torch.cat((xf,x2), dim = 1)
    x = torch.flatten(xf)
    x = self.fc(x)
    x = self.clf(x)
    return x

#### MODEL :- 7 #####

import torch
import torch.nn as nn

class ResBlock(nn.Module):
  def __init__(self, num_ft = 64, kernel_size = 3, stride = 1, padding = 1):
    super(ResBlock, self).__init__()
    m = []
    for _ in range(2):
      m.append(nn.Conv1d(num_ft, num_ft, kernel_size, stride, padding))
      m.append(nn.BatchNorm1d(num_ft))
      m.append(nn.ReLU())
    self.body = nn.Sequential(*m)

  def forward(self, x):
    res = self.body(x)
    res += x
    return res





class ResedualLSTMEEGClassifier_3(nn.Module):
  def __init__(self, num_channels,  num_classes, num_res_ft = 64, num_res = 2, input_size = 16,
               hidden_size = 128, sequence_length = 8, num_layers = 1):
    super(ResedualLSTMEEGClassifier_3, self).__init__()
    self.conv = nn.Conv1d(num_channels, num_res_ft, kernel_size = 3, stride = 1, padding = 0)
    self.res = ResBlock()
    self.num_layers = num_layers
    self.hidden_size = hidden_size
    mat = []
    for _ in range(num_res):
      mat.append(ResBlock(num_ft = num_res_ft))
      mat.append(nn.RReLU())
    self.res_body_1 = nn.Sequential(*mat) 

    self.conv2 = nn.Conv1d(num_res_ft, num_res_ft*2, kernel_size = 3, stride = 1, padding = 0)

    mat2 = []
    for _ in range(num_res):
      mat2.append(ResBlock(num_ft = num_res_ft*2))
      mat2.append(nn.RReLU())
    self.res_body_2 = nn.Sequential(*mat2) 
    self.conv3 = nn.Conv1d(num_res_ft*2, num_res_ft*4, kernel_size = 3, stride = 1, padding = 0)

    mat3 = []
    for _ in range(num_res):
      mat3.append(ResBlock(num_ft = num_res_ft*4))
      mat3.append(nn.RReLU())
    self.res_body_3 = nn.Sequential(*mat3) 
    self.conv4 = nn.Conv1d(num_res_ft*4, num_res_ft*8, kernel_size = 3, stride = 1, padding = 0)

    mat4 = []
    for _ in range(num_res):
      mat4.append(ResBlock(num_ft = num_res_ft*8))
      mat4.append(nn.RReLU())
    self.res_body_4 = nn.Sequential(*mat4) 

    self.avg = nn.AdaptiveAvgPool1d(1)
    self.maxpool = nn.MaxPool1d(1)

    self.lstm = nn.LSTM(input_size , hidden_size, num_layers, batch_first = True)

    self.fc = nn.Linear(hidden_size*sequence_length, num_classes)
    self.clf = nn.Softmax()

  def forward(self, x):
    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()
    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()

    x = self.conv(x)
    x = self.res_body_1(x)
    x = self.conv2(x)
    x = self.res_body_2(x)
    x = self.conv3(x)
    x = self.res_body_3(x)
    #x = self.conv4(x)
    #x = self.res_body_4(x)
    x = self.avg(x)
    x = x.reshape(x.size(0), 8, 16)
    x,_ = self.lstm(x, (h0, c0))
    x = torch.flatten(x)
    x = self.fc(x)
    x = self.clf(x)
    return x

#### Model : Comparison #####
import torch
import torch.nn as nn

class Comparison_LSTM(nn.Module):
  def __init__(self, num_channels = 4, embedding_dimension = 256, hidden_size = 128, num_classes = 2, num_layers = 1):
    super(Comparison_LSTM, self).__init__()

    self.num_layers = num_layers
    self.hidden_size = hidden_size
    self.sequence_length = num_channels
    #self.embedding = nn.Embedding(self.sequence_length, embedding_dimension)    
    self.lstm = nn.LSTM(embedding_dimension , hidden_size, num_layers, batch_first = True)
    self.fc = nn.Linear(hidden_size*self.sequence_length, num_classes)
    self.clf = nn.Softmax()

  def forward(self, x):
    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)#.cuda()
    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)#.cuda()

    #x = torch.LongTensor(x.reshape(x.size(0), num_channels, -1))
    x = x.reshape(x.size(0),-1)
    print('x1:', x.shape)
    print('yes1:',1)
    x = self.embedding(x) 
    print('yes2:',2)
    x,_ = self.lstm(x, (h0, c0))
    x = torch.flatten(x,1)
    x = self.fc(x)
    x = self.clf(x)

    return x

import pickle
with open('/content/drive/My Drive/Data/Data.pkl', 'rb') as f:
    df_nve = pickle.load(f)

with open('/content/drive/My Drive/Data/Data_E1_pve.pkl', 'rb') as f:
    df_pve = pickle.load(f)

#Alpha signal
import numpy as np
data_nve = []
for i in range(len(df_nve)):
  data_2_channels = []
  data_2_channels.append(np.array(df_nve[0])[i].transpose()[12])#F3
  data_2_channels.append(np.array(df_nve[0])[i].transpose()[7])#F4
  data_2_channels.append(np.array(df_nve[0])[i].transpose()[11])#F7
  data_2_channels.append(np.array(df_nve[0])[i].transpose()[9])#F8
  #data_2_channels.append(np.array(df_nve[0])[i].transpose()[6])#Fz
  #data_2_channels.append(np.array(df_nve[0])[i].transpose()[14])#T7
  #data_2_channels.append(np.array(df_nve[0])[i].transpose()[3])#T8
  data_nve.append(np.array(data_2_channels).transpose())


data_pve = []
for i in range(len(df_pve)):
  data_2_channels = []
  data_2_channels.append(np.array(df_pve[0])[i].transpose()[12])#F3
  data_2_channels.append(np.array(df_pve[0])[i].transpose()[7])#F4
  data_2_channels.append(np.array(df_pve[0])[i].transpose()[11])#F7
  data_2_channels.append(np.array(df_pve[0])[i].transpose()[9])#F8
  #data_2_channels.append(np.array(df_pve[0])[i].transpose()[6])#Fz
  #data_2_channels.append(np.array(df_pve[0])[i].transpose()[14])#T7
  #data_2_channels.append(np.array(df_pve[0])[i].transpose()[3])#T8
  data_pve.append(np.array(data_2_channels).transpose())

import pandas as pd
df = [df_nve, df_pve]
df = pd.concat(df,ignore_index=True)
print(df)



label_pve = []
for i in range(len(df_pve)):
  label_pve.append(0)
print('pve: ', len(label_pve))


label_nve = []
for i in range(len(df_nve)):
  label_nve.append(1)
print('nve: ', len(label_nve))

labels = label_nve + label_pve
print('label: ',len(labels))

pve_test_points = 40
nve_test_points = 60
#pve_train_points = 
nve_train_points = 300

label_nve_test = label_nve[0:nve_test_points]
print('label_nve_test',len(label_nve_test))
label_pve_test = label_pve[0:pve_test_points]
print('label_pve_test',len(label_pve_test))
df_pve_test =  np.array(data_pve[0:pve_test_points])
print('df_pve_test',len(df_pve_test))
df_nve_test =  np.array(data_nve)[0:nve_test_points]
print('df_nve_test',len(df_nve_test))


label_nve_train = label_nve[nve_test_points:nve_train_points]
print('label_nve_train',len(label_nve_train))
label_pve_train = label_pve[pve_test_points:]
print('label_pve_train',len(label_pve_train))
df_pve_train =  np.array(data_pve)[pve_test_points:]
print('df_pve_train',len(df_pve_train))
df_nve_train =  np.array(data_nve)[nve_test_points:nve_train_points]
print('df_nve_train',len(df_nve_train))

train_data = np.concatenate((df_nve_train, df_pve_train))
print('train_data: ', len(train_data))
train_label = np.concatenate((label_nve_train, label_pve_train))
print('train_label: ', len(train_label))
test_data = np.concatenate((df_nve_test, df_pve_test))
print('test_data: ', len(test_data))
test_label = np.concatenate((label_nve_test, label_pve_test))
print('test_label: ', len(test_label))

num_epoch = 600
lr = 0.0001
momentum = 0.5155397451642598
num_channels = 4
num_residual_features = 64
num_resedual_blocks = 3
device = torch.device('cuda' if torch.cuda.is_available else 'cpu')
model = Comparison_LSTM()
model = model.cuda()
optimizer = torch.optim.Adam(model.parameters(), lr = lr)
criterion = nn.CrossEntropyLoss()

for epoch in range(num_epoch):
  train_loss = 0.0
  correct = total = 0
  for i in range(len(train_data)):
    print('data: ', i)
    optimizer.zero_grad()
    data_point, label = torch.tensor(train_data[i]), torch.tensor(np.array([train_label[i]]))
    data_point, label = data_point.cuda(), label.cuda()
    data_point = data_point.reshape(1,num_channels,-1)
    #print(data_point.shape)
    output = model(data_point.long())
    #print(output.shape)
    #print(label.shape)
    loss = criterion(output.reshape(1,-1), label)
    #print(loss)
    loss.backward()
    optimizer.step()
    train_loss += loss.item()
    _, predicted = torch.max(output.reshape(1,-1).data, 1)
    total += label.size(0)
    correct += (predicted == label).sum().item()

  print('Training Epoch: ', epoch)
  print('training loss: ', train_loss)
  print('Accuracy: ', 100*correct/total)

  with torch.no_grad():
    val_loss = 0.0
    total = correct = 0
    for j in range(len(test_data)):
      val_data, val_label = torch.tensor(test_data[j]), torch.tensor(np.array([test_label[j]]))
      val_data, val_label = val_data.cuda(), val_label.cuda()
      val_data = val_data.reshape(1,num_channels,-1)
      out_val = model(val_data.float())
      loss = criterion(out_val.reshape(1,-1), val_label)
      val_loss += loss.item()
      _, predicted_val = torch.max(out_val.reshape(1,-1).data, 1)
      total += val_label.size(0)
      correct += (predicted_val == val_label).sum().item()
      #print('prediction: ',predicted_val)
      #print('label: ', val_label)
  print('Validation Loss: ', val_loss)
  print('Validation Accuracy: ', 100*correct/total)

##CPU Only ##
num_epoch = 600
lr = 0.0001
momentum = 0.5155397451642598
num_channels = 4
num_residual_features = 64
num_resedual_blocks = 3
device = torch.device('cuda' if torch.cuda.is_available else 'cpu')
model = Comparison_LSTM()
#model = model#.cuda()
optimizer = torch.optim.Adam(model.parameters(), lr = lr)
criterion = nn.CrossEntropyLoss()

for epoch in range(num_epoch):
  train_loss = 0.0
  correct = total = 0
  for i in range(len(train_data)):
    print('data: ', i)
    optimizer.zero_grad()
    data_point, label = torch.tensor(train_data[i]), torch.tensor(np.array([train_label[i]]))
    data_point, label = data_point, label
    data_point = data_point.reshape(1,num_channels,-1)
    #print(data_point.shape)
    output = model(data_point.long())
    #print(output.shape)
    #print(label.shape)
    loss = criterion(output.reshape(1,-1), label)
    #print(loss)
    loss.backward()
    optimizer.step()
    train_loss += loss.item()
    _, predicted = torch.max(output.reshape(1,-1).data, 1)
    total += label.size(0)
    correct += (predicted == label).sum().item()

  print('Training Epoch: ', epoch)
  print('training loss: ', train_loss)
  print('Accuracy: ', 100*correct/total)

  with torch.no_grad():
    val_loss = 0.0
    total = correct = 0
    for j in range(len(test_data)):
      val_data, val_label = torch.tensor(test_data[j]), torch.tensor(np.array([test_label[j]]))
      val_data, val_label = val_data, val_label
      val_data = val_data.reshape(1,num_channels,-1)
      out_val = model(val_data.float())
      loss = criterion(out_val.reshape(1,-1), val_label)
      val_loss += loss.item()
      _, predicted_val = torch.max(out_val.reshape(1,-1).data, 1)
      total += val_label.size(0)
      correct += (predicted_val == val_label).sum().item()
      #print('prediction: ',predicted_val)
      #print('label: ', val_label)
  print('Validation Loss: ', val_loss)
  print('Validation Accuracy: ', 100*correct/total)

embedding = nn.Embedding(6, 3, padding_idx=0)
input = torch.LongTensor([[0,2,0,5]])
print(input.shape)
print(embedding(input).shape)

